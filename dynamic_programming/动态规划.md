#### 动态规划
* 动态规划（dynamic programming）与分治方法相似，都是通过组合子问题的解来求解原问题（在 这里，“programming" 指的是一种表格法，并非编写计算机程序）。
* **分治方法将问题划分为互不相交的子问题，递归地求解子问题，再将它们的解组合起来，求出原问题的解。与之相反，动态规划应用于子问题重叠的情况，即不同的子问题具有公共的子子问题（子问题的求解是递归进行的，将其划分为更小的子子问题）。在这种情况下，分治算法会做许多不必要的工作，它会反复地求解那些公共子子问题。而动态规划算法对每个子子问题只求解一次，将其解保存在一个表格中，从而无需每次求解一个子子问题时都重新计算，避免了这种不必要的计算工作。**
  * 记忆
  * 备忘录
* 动态规划方法通常用来求解**最优化问题（optimization problem）**.这类问题可以有很多可行解，每个解都有一个值，我们希望寻找具有最优值（最小值或最大值）的解。我们称这样的解为问题的一个最优解（an optimal solution）,而不是最优解（the optimal solution）,因为可能有多个解都达到最优值。

* 我们通常按如下4个步骤来设计一个动态规划算法：

  1. 刻画一个**最优解的结构特征**。

  2. **递归地定义最优解的值**。
  3. 计算最优解的值，通常采用**自底向上**的方法。

  4. 利用计算出的信息构造一个最优解。

  * 步骤1〜3是动态规划算法求解问题的基础。如果我们仅仅需要一个最优解的值，而非解本身，可以忽略步骤4。如果确实要做步骤4,有时就需要在执行步骤3的过程中维护一些额外信 息，以便用来构造一个最优解。
* 动态规划有两种等价的实现方法
    * 第一种方法称为带备忘的自顶向下法(top-down with memoization)**， 此方法仍按自然的递 归形式编写过程，但过程会保存每个子问题的解(通常保存在一个数组或散列表中)。当需要一个子问题的解时，过程首先检査是否已经保存过此解。如果是，则直接返回保存的值，从而节省了 计算时间；否则，按通常方式计算这个子问题。我们称这个**递归过程是带备忘的**(memoized), 因为它“记住"了之前已经计算出的结果。
    * 第二种方法称为**自底向上法(bottonrup method).**这种方法一般**需要恰当定义子问题“规模” 的概念，使得任何子问题的求解都只依赖于“更小的”子问题的求解**。因而我们**可以将子问题按规模排序，按由小至大的顺序进行求解。当求解某个子问题时，它所依赖的那些更小的子问题都已求解完毕，结果已经保存。每个子问题只需求解一次，当我们求解它(也是第一次遇到它〉时，它的所有前提子问题都已求解完成。**
    两种方法得到的算法具有相同的渐近运行时间，仅有的差异是在某些特殊情况下，自顶向下方法并未真正递归地考察所有可能的子何题。由于没有频繁的递归函数调用的开销，自底向上方法的时间复杂性函数通常具有更小的系数。
##### 子问题图

* 当思考一个动态规划问题时，我们应该弄清所涉及的子问题及子问题之间的依赖关系,问题的子问题图准确地表达了这些信息。它是一个有向图，每个顶点唯一地对应一个子问题。 若求子问题x的最优解时需要直接用到子问题 y 的最优解，那么在子问题图中就会有一条从子问题x的顶点到子问题y的顶点的有向边。例如，如果自顶向下过程在求解x时需要直接递归调用自身来求解y，那 么子问题图就包含从x到y的一条有向边。我们可以将子问题图看做自顶向下递归调用树的“简化版”或 “收缩版”，因为树中所有对应相同子问题的结点合并为图中的单一顶点，相关的所有边都从父结点指向子节点。

* 自底向上的动态规划方法处理子问题图中顶点的顺序为：**对于一个给定的子问题x，在求解它之前求解邻接至它的子问题y（邻接关系不一定是对称的）。动态规划算法是按逆拓扑序的来处理子问题图中的顶点**。换句话说，对于任何子问题，直至它依赖的所有子问题均已求解完成，才会求解它。

* 类似地，我们可以用“深度优先搜索"（depth-first search）来描述（带备忘机制的）自顶向下动态规划 算法处理子问题图的顺序。

* 子问题图G=（V, E）的规模可以帮助我们确定动态规划算法的运行时间。由于每个子问题 只求解一次，因此算法运行时间等于每个子问题求解时间之和。通常，一个子问题的求解时间与 子问题图中对应顶点的度（出射边的数目）成正比，而子问题的数目等于子问题图的顶点数。因 此，通常情况下，动态规划算法的运行时间与顶点和边的数量呈线性关系。

* **重构解**  动态规划算法返回最优解的收益值，但并未返回解本身。我们可以扩展动态规划算法，使之对每个子冋题不仅保存最优收益值，还保存对应的方案。利用这些信息，我们就能输出最优解。
#### 动态规划原理

* 适合应用动态规划方法求解的最优化问题应该具备的两个要素：最优子结构和子问题重叠。

##### 最优子结构

* 用动态规划方法求解最优化问题的第一步就是刻画最优解的结构。如果一个 问题的最优解包含其子问题的最优解，我们就称此问题具有最优子结构性质。因此，某个问题是否适合应用动态规划算法，它是否具有最优子结构性质是一个好线索（当然，具有最优子结构性质也可能意味着适合应用贪心策略）。**使用动态规划方法时，我们用子问题的最优解来构造原问题的最优解。因此，我们必须小心确保考察了最优解中用到的所有子问题。**

* 在发掘最优子结构性质的过程中，实际上遵循了如下的通用模式：

  1. 证明问题最优解的**第一个组成部分是做出一个选择，做出这次选择会产生一个或多个待解的子问题**。
  2. 对于一个给定问题，在其可能的第一步选择中，你**假定已经知道哪种选择才会得到最优解。你现在并不关心这种选择具体是如何得到的，只是假定已经知道了这种选择**
  3. 给定可获得最优解的选择后，你确定**这次选择会产生哪些子问题，以及如何最好地刻画子问题空间**。
  4. 利用**“剪切一粘贴"（cut-and-paste）**技术证明：作为构成原问题最优解的组成部分，每个子问题的解就是它本身的最优解。证明这一点是利用反证法：假定子问题的解不是其自身的最优解，那么我们就可以从原问题的解中“剪切”掉这些非最优解，将最优解“粘贴”进去，从而得到原问题一个更优的解，这与最初的解是原问题最优解的前提假设矛盾。如果原问题的最优解包含多个子问题，通常它们都很相似，我们可以将针对一个子问题的“剪切一粘贴”论证方法稍加修改，用于其他子问题。

* 一个刻画子冋题空间的好经验是：保持子问题空间尽可能简单，只在必要时才扩展它。

* 对于不同问题领域，最优子结构的不同体现在两个方面：

  1. **原问题的最优解中涉及多少个子问题**

  2. **在确定最优解使用哪些子问题时，我们需要考察多少种选择**

* 我们可以**用子问题的总数和每个子问题需要考察多少种选择这两个因素的乘积来粗略分析动态规划算法的运行时间**。

  * 对于钢条切割问题，共有  $\Theta(n)$ 个子问题，每个子问题最多需要考察n种选择，因此运行时间为$ O(n^2) $.  矩阵链乘法问题共有$\Theta(n^2)$个子问题，每个子问题最多需要考察 n - 1种选择，因此运行时间为$O(n^3)$.

* 子问题图也可用来做同样的分析。图中每个顶点对应一个子问题，而需要考察的选择对应关联至子问题顶点的边。回忆一下，钢条切割问题的子问题图有 n 个顶点，每个顶点最多 n-1条边，因此运行时间为$O(n^2) $。对于矩阵链乘法问题，子问题图会有$O(n^2)$个顶点，而每个顶点最 多有 n-1 条边，因此共有$O(n^3) $个顶点和边。

* 在动态规划方法中，我们通常自底向上地使用最优子结构。也就是说，首先求得子问题的最优解，然后求原问题的最优解。在求解原问题过程中，我们**需要在涉及的子问题中做出选择，选出能得到原问题最优解的子问题**。**原问题最优解的代价通常就是子问题最优解的代价再加上由此次选择直接产生的代价。**

* “贪心算法”，它与动态规划有很多相似之处。特别是，**能够应用贪心算法的问题也必须具有最优子结构性质**。贪心算法和动态规划最大的不同在于，它**并不是首先寻找子问题的最优解，然后在其中进行选择，而是首先做出一次“贪心”选择(在当时（局部）看来最优的选择). —— 然后求解选出的子问题，从而不必费心求解所有可能相关的子问题。**令人惊讶的是，在某些情况下这一策略也能得到最优解！

* 最长简单路径问题与最短路径问题分析

  * 为什么最长简单路径问题的子结构与最短路径有这么大的差别？原因在于，虽然最长路径问题和最短路径问题的解都用到了两个子问题，但两个最长简单路径子问题是相关的，而两个 最短路径子问题是无关的（independent）.
* **子问题无关的含义是，同一个原问题的一个子 问题的解不影响另一个子问题的解。子问题是相关的，求解一个子问题时用到了某些资源（在本例中是顶点），导致这些资源在求解其他子问题时不可用。**

##### 子问题重叠

* 适合用动态规划方法求解的最优化问题应该具备的第二个性质是**子问题空间必须足够“小”**， 即**问题的递归算法会反复地求解相同的子问题，而不是一直生成新的子问题**。一般来讲，不同子问题的总数是输入规模的多项式函数友好。如果递归算法反复求解相同的子问题，我们就称最优化问题具有**重査子问题(overlapping subproblems)性质**。与之相对的，适合**用分治方法求解的 问题通常在递归的每一步都生成全新的子问题。**动态规划算法通常这样利用重叠子问题性质； **对每个子问题求解一次，将解存入一个表中，当再次需要这个子问题时直接査表，每次査表的代价为常量时间。**
* 动态规划算法对每 个子问题只求解一次。而递归算法则相反，对每个子问题，每当在递归树中(递归调用时)遇到 它，都要重新计算一次。凡是一个问题的自然递归算法的递归调用树中反复出现相同的子问题，而不同子问题的总数很少时，动态规划方法都能提高(有时还是极大地提高)效率。

##### 重构最优解

* 从实际考虑，我们通常将每个子问题所做的选择存在一个表中，这样就不必根据代价值来重构这些信息。

##### 备忘

* 我们可以保持自顶向下策略，同时达到与自底向上 动态规划方法相似的效率。思路就是对自然但低效的递归算法加入备忘机制。与自底向上方法 一样，我们维护一个表记录子问题的解，但仍保持递归算法的控制流程。

* 带备忘的递归算法为每个子问题维护一个表项来保存它的解。每个表项的初值设为一个特 殊值，表示尚未填入子问题的解。当递归调用过程中第一次遇到子问题时，计算其解，并存入对 应表项。随后每次遇到同一个子问题，只是简单地査表，返回其解。

  * 这种方法假定我们預先已经知道所有可能的子问题参数(子何題空间)，并已在表项和子问题间建立起对应关系。 另一个更通用的备忘方法是使用散列技术，以子问题参数为关键字.

* 通常情况下，如果每个子问题都必须至少求解一次，自底向上动态规划算法会比自顶向下 备忘算法快(相差一个常量系数)，因为自底向上算法没有递归调用的开销，表的维护开销也更小。而且，对于某些问题，我们可以利用表的访问模式来进一步降低时空代价。 相反，**如果子问题空间中的某些子问题完全不必求解，备忘方法就会体现出优势了，因为它只会求解那些绝对必要的子问题。**

  

#### 最长公共子序列

* 一个给定序列的子序列，就是将给定 序列中零个或多个元素去掉之后得到的结果。
* 给定两个序列X和Y，如果Z既是X的子序列，也是Y的子序列，我们称它是X和Y的公共子序列(common subsequence)
* 如果用暴力搜索方法求解LCS问题，就要穷举X的所有子序列，对每个子序列检査它是否 也是Y的子序列，记录找到的最长子序列。X的每个子序列对应X的下标集合 {1, 2,..., m}的一个子集，所以X有 $2^m$ 个子序列，因此暴力方法的运行时间为指数阶，对较长的序列是不实用的。
* 动态规划求解
  * 刻画最长公共子序列的特征： LCS的最优子结构
  * —个递归解
  * 计算LCS的长度
  * 构造LCS
  * 算法改进
    * —旦设计出一个算法，通常情况下你都会发现它在时空开销上有改进的余地。一些改进可 以简化代码，将性能提高常数倍，但除此之外不会产生性能方面的渐近性提升。而另一些改进可 以带来时空上巨大的渐近性提升。

#### 最优二叉搜索树

* 假定我们正在设计一个程序，实现英语文本到法语的翻译。对英语文本中出现的每个单词， 我们需要査找对应的法语单词。为了实现这些査找操作，我们可以创建一棵二叉搜索树，将*个 英语单词作为关键字，对应的法语单词作为关联数据。由于对文本中的每个单词都要进行搜索， 我们希望花费在搜索上的总时间尽量少。通过使用红黑树或其他平衡搜索树结构，我们可以假 定每次搜索时间为 $\Theta(lgn)$ .但是，单词出现的频率是不同的，像“the”这种频繁使用的单词有可 能位于搜索树中远离根的位置上，而像“machicolation”这种很少使用的单词可能位于靠近根的位 置上。这样的结构会减慢翻译的速度，因为在二叉树搜索树中捜索一个关键字需要访问的结点 数等于包含关键字的结点的深度加1。我们希望文本中频繁出现的单词被置于靠近根的位置 而且，文本中的一些单词可能没有对应的法语单词,这些单词根本不应该出现在二叉搜索树 中。在给定单词出现频率的前提下，我们应该如何组织一棵二叉搜索树，使得所有搜索操作访问 的结点总数最少呢？
* 对于一个给定的概率集合，我们希望构造一棵期望搜索代价最小的二叉搜索树，我们称之为最优二叉搜索树。最优二叉搜索树不一定是高度最矮的。而且，概率最 高的关键字也不一定出现在二叉搜索树的根结点。由于我们知道每个关键字和伪关键字的搜索概率，因而可以确定在一棵给定的二叉搜索树 T 中进行一次搜索的期望代价。假定一次搜索的代价等于访问的结点数，即此次搜索找到的结点 在T中的深度再加1。
* 矩阵链乘法问题相似，对本问题来说，穷举并检查所有可能的二叉搜索树不是一个高 的算法。对任意一棵 n 个结点的二叉树，我们都可以通过对结点标记关键字来构造 出一棵二叉搜索树，然后向其中添加伪关键字作为叶结点。
* 

